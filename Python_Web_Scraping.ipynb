{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Web Scraping\n",
    "Programming assignment for INST447 <br>\n",
    "Goal: Extract the first page of job posts of given titles and locations, then export to a csv file<br>\n",
    "Website: Indeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "from time import time, sleep\n",
    "from random import randint\n",
    "from warnings import warn\n",
    "from IPython.core.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Modifying the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of target urls\n",
    "jobs = [\"Data Analyst\", \"Data Scientist\", \"Database Administrator\", \"Machine Learning Engineer\", \"Data Engineer\"]\n",
    "states = [\"Virginia\", \"New York State\", \"California\", \"Texas\", \"Washington State\"]\n",
    "\n",
    "# Replace spaces with + for url compatibility\n",
    "jobs = [i.replace(\" \", \"+\") for i in jobs]\n",
    "states = [i.replace(\" \", \"+\") for i in states]\n",
    "\n",
    "# Build list of all urls required\n",
    "urls = []\n",
    "for j in jobs:\n",
    "    for s in states:\n",
    "        urls.append(\"https://www.indeed.com/jobs?q=\" + j  +\"&l=\" + s + \"&sort=date\")\n",
    "        \n",
    "# Lists for storing variables\n",
    "titles = []\n",
    "companies = []\n",
    "ratings = []\n",
    "locations = []\n",
    "wages = []\n",
    "descriptions = []\n",
    "post_times = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Extracting the Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request:25; Frequency: 0.08549822300196386 requests/s\n"
     ]
    }
   ],
   "source": [
    "# Loop for requests\n",
    "requests = 0\n",
    "start_time = time()\n",
    "for u in urls:\n",
    "    # Make a get request\n",
    "    response = get(u)\n",
    "        \n",
    "    # Pause the loop\n",
    "    sleep(randint(8,15))\n",
    "\n",
    "    # Monitor the requests\n",
    "    requests += 1\n",
    "    elapsed_time = time() - start_time\n",
    "    print('Request:{}; Frequency: {} requests/s'.format(requests, requests/elapsed_time))\n",
    "    clear_output(wait = True)\n",
    "\n",
    "    # Throw a warning for non-200 status codes\n",
    "    if response.status_code != 200:\n",
    "        warn('Request: {}; Status code: {}'.format(requests, response.status_code))\n",
    "\n",
    "    # Break the loop if the number of requests is greater than expected\n",
    "    if requests > 100:\n",
    "        warn('Number of requests was greater than expected.')\n",
    "        break\n",
    "    \n",
    "    # Parse html\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    job_containers = soup.find_all('div', {'class':{'jobsearch-SerpJobCard unifiedRow row result'}})\n",
    "    \n",
    "    # Loop through each job and extract data; append 'Missing' if job does not have certain data\n",
    "    for job in job_containers:\n",
    "        # Job Title\n",
    "        try:\n",
    "            title = job.find('a', {'class':{'jobtitle turnstileLink'}})\n",
    "            titles.append(title.text)\n",
    "        except:\n",
    "            titles.append('Missing')\n",
    "            \n",
    "        # Company Name\n",
    "        try:\n",
    "            company = job.find('span', {'class':{'company'}})\n",
    "            companies.append(company.text)\n",
    "        except:\n",
    "            companies.append('Missing')\n",
    "            \n",
    "        # Job Location\n",
    "        try:\n",
    "            location = job.find(['span','div'], {'class':{'location accessible-contrast-color-location'}})\n",
    "            locations.append(location.text)\n",
    "        except:\n",
    "            locations.append('Missing')\n",
    "            \n",
    "        # Job Wage/Salary\n",
    "        try:\n",
    "            wage = job.find('span', {'class':{'salaryText'}})\n",
    "            wages.append(wage.text)\n",
    "        except:\n",
    "            wages.append('Missing')\n",
    "            \n",
    "        # Job Description\n",
    "        try:\n",
    "            summary = job.find('div', {'class':{'summary'}})\n",
    "            descriptions.append(summary.text)\n",
    "        except:\n",
    "            descriptions.append('Missing')\n",
    "            \n",
    "        # Posting Date\n",
    "        try:\n",
    "            date = job.find('span', {'class':{'date'}})\n",
    "            post_times.append(date.text)\n",
    "        except:\n",
    "            post_times.append('Missing')\n",
    "            \n",
    "        # Company rating\n",
    "        try:\n",
    "            rating = job.find('span', {'class':{'ratingsContent'}})\n",
    "            ratings.append(rating.text)\n",
    "        except:\n",
    "            ratings.append('Missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Data Manipulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Date of Posting</th>\n",
       "      <th>Company Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Publications Data Analyst</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Falls Church, VA</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Keywords: Federal contacts, Procurement, Data ...</td>\n",
       "      <td>Just posted</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EOC Business Analyst</td>\n",
       "      <td>CACI</td>\n",
       "      <td>Arlington, VA 22201</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Coordinate with cross-functional teams to asce...</td>\n",
       "      <td>Just posted</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Office Administrator / Jr. Business Analyst</td>\n",
       "      <td>Venesco, LLC</td>\n",
       "      <td>Falls Church, VA</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Conduct relevant research, data analysis, and ...</td>\n",
       "      <td>Just posted</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lead Data and Analytic Modeler, Customer Analy...</td>\n",
       "      <td>KPMG</td>\n",
       "      <td>McLean, VA 22102</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Work with clients to discover data sources, an...</td>\n",
       "      <td>Just posted</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Analyst I</td>\n",
       "      <td>Fairfax County Government</td>\n",
       "      <td>Fairfax, VA 22035</td>\n",
       "      <td>$54,219 - $90,366 a year</td>\n",
       "      <td>Integrates data from various sources into the ...</td>\n",
       "      <td>Today</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                          Publications Data Analyst   \n",
       "1                               EOC Business Analyst   \n",
       "2        Office Administrator / Jr. Business Analyst   \n",
       "3  Lead Data and Analytic Modeler, Customer Analy...   \n",
       "4                                 Business Analyst I   \n",
       "\n",
       "                Company Name         Job Location                    Salary  \\\n",
       "0            Piper Companies     Falls Church, VA                   Missing   \n",
       "1                       CACI  Arlington, VA 22201                   Missing   \n",
       "2               Venesco, LLC     Falls Church, VA                   Missing   \n",
       "3                       KPMG     McLean, VA 22102                   Missing   \n",
       "4  Fairfax County Government    Fairfax, VA 22035  $54,219 - $90,366 a year   \n",
       "\n",
       "                                     Job Description Date of Posting  \\\n",
       "0  Keywords: Federal contacts, Procurement, Data ...     Just posted   \n",
       "1  Coordinate with cross-functional teams to asce...     Just posted   \n",
       "2  Conduct relevant research, data analysis, and ...     Just posted   \n",
       "3  Work with clients to discover data sources, an...     Just posted   \n",
       "4  Integrates data from various sources into the ...           Today   \n",
       "\n",
       "  Company Rating  \n",
       "0            4.5  \n",
       "1            3.8  \n",
       "2            3.5  \n",
       "3            4.0  \n",
       "4            4.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Framing data and replacing newline escapes, printing first 5 rows\n",
    "job_data = pd.DataFrame({\n",
    "    \"Job Title\": titles,\n",
    "    \"Company Name\": companies,\n",
    "    \"Job Location\": locations,\n",
    "    \"Salary\": wages,\n",
    "    \"Job Description\": descriptions,\n",
    "    \"Date of Posting\": post_times,\n",
    "    \"Company Rating\": ratings\n",
    "})\n",
    "\n",
    "job_data = job_data.replace('\\n','', regex=True)\n",
    "job_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting job location into separate columns, adding it to data frame\n",
    "cities = [i.split(\",\")[0] for i in job_data[\"Job Location\"]]\n",
    "states = []\n",
    "for i in job_data[\"Job Location\"]:\n",
    "    try:\n",
    "        states.append(i.split(',')[1][1:])\n",
    "    except:\n",
    "        states.append('Missing')\n",
    "        \n",
    "job_data[\"City\"] = cities\n",
    "job_data[\"State/Zip\"] = states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City\n",
      "Albany              0.266667\n",
      "Alexandria          0.266667\n",
      "Anacortes           0.266667\n",
      "Arlington           3.200000\n",
      "Armonk              0.533333\n",
      "                      ...   \n",
      "Vienna              0.533333\n",
      "Virginia            0.266667\n",
      "Washington State    0.533333\n",
      "Westlake            0.800000\n",
      "Willits             0.266667\n",
      "Name: City, Length: 102, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Print the percentage of Jobs in each city using the value counts function.\n",
    "print((job_data[\"City\"].groupby(job_data[\"City\"]).count()/len(job_data))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data frame as a CSV file.\n",
    "job_data.to_csv('Mannix_Colin_INST447_PA2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
